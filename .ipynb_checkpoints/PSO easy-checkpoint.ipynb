{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46160e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quantecon as qe\n",
    "from ast import literal_eval\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05947d9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def creating_samples(samples_number, element):\n",
    "    gen=0\n",
    "    uniform_number = len(element)\n",
    "    uniform_samples = (-qe.simplex_grid(len(element), 1)+1)/(len(element)-1)\n",
    "    if samples_number > uniform_number:\n",
    "        random_samples = np.random.rand((samples_number-uniform_number), len(element))\n",
    "        for i in range(samples_number-uniform_number):\n",
    "            random_samples[i] = np.around(random_samples[i]/sum(random_samples[i]), decimals = 3)\n",
    "        sample = np.vstack((uniform_samples, random_samples))\n",
    "    else:\n",
    "        sample = uniform_samples[:samples_number]\n",
    "    samples = []\n",
    "    for i in range(samples_number):\n",
    "        samples.append(list(sample[i]))\n",
    "    samples = np.array(samples)\n",
    "    generation = []\n",
    "    for i in range (samples_number):\n",
    "            generation.append(gen)\n",
    "\n",
    "    ID = np.arange(1, (samples_number+1))\n",
    "\n",
    "    data = {'ID' : ID, 'Elements': [element], 'Generation': generation}\n",
    "    df = pd.DataFrame(data=data, index = np.arange(samples_number))\n",
    "    df = pd.concat([df, pd.DataFrame(([[i] for i in samples]), columns = ['Position'])], axis = 1)\n",
    "    df.to_csv(\"Result/Initial Population.txt\", sep='\\t', index=False, mode='w')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data and fitting\n",
    "df_old = pd.read_csv('Data/AuIrOsPdPtReRhRu_0.60_compositions_and_targets.csv')\n",
    "X_columns_old = ['Pt','Pd','Au','Ru','Rh','Ir','Re','Os']\n",
    "x_old = df_old[X_columns_old].to_numpy()\n",
    "y_old = df_old['current_over_capacitance'].to_numpy()\n",
    "\n",
    "#Rndom Forest Regression\n",
    "reg = RandomForestRegressor(n_estimators = 1024,\n",
    "                           bootstrap = True,\n",
    "                           max_depth = None,\n",
    "                           max_features = 'auto',\n",
    "                           min_samples_leaf = 1,\n",
    "                           min_samples_split = 2,\n",
    "                           oob_score = True)\n",
    "reg = reg.fit(x_old, y_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bf7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Class\n",
    "class pso:\n",
    "    def __init__ (self, data, step, target = np.array([0.333, 0.333, 0.333])):\n",
    "        self.datalog = data\n",
    "        #Reading \"Elements\" columns from string to list\n",
    "        self.datalog['Elements'] = self.datalog[\"Elements\"].apply(lambda x: literal_eval(x))\n",
    "        \n",
    "        #Select latest generation\n",
    "        self.generation = self.datalog['Generation'].max()\n",
    "        \n",
    "        #Creating np.array of \"Position\" column and dropping the string type \"Position\" column\n",
    "        self.position = []\n",
    "        for i in range(self.datalog['ID'].max()):\n",
    "            self.position.append(list(np.fromstring(self.datalog['Position'][i][1:-1], dtype=float, sep=' ')))\n",
    "        self.position = np.array(self.position)\n",
    "        self.datalog = self.datalog.drop(columns=['Position'])\n",
    "        self.datalog = pd.concat([self.datalog, pd.DataFrame(([[i] for i in self.position]), columns = ['Position'])], axis = 1)\n",
    "        \n",
    "        #Creating \"Velocity\" column for the \"0\" generation\n",
    "        if self.generation == 0:\n",
    "            self.velocity = np.around((-(self.position - target)/step), decimals = 3)\n",
    "            self.datalog = pd.concat([self.datalog, pd.DataFrame(([[i] for i in self.velocity]), columns = ['Velocity'])], axis = 1)\n",
    "        \n",
    "        #Creating blank \"Activity\" column\n",
    "        self.datalog = pd.concat([self.datalog, pd.DataFrame(columns = ['Activity'], index = np.arange(self.datalog['ID'].max()))], axis = 1)      \n",
    "\n",
    "        #Filling the \"Activity\" column with RFR\n",
    "        self.f_activity(self.datalog)\n",
    "            \n",
    "        #Creating dataframe of the latest generation\n",
    "        self.working_generation = self.datalog.loc[self.datalog['Generation']==self.generation]\n",
    "    \n",
    "    \n",
    "            \n",
    "    def move(self, size=1):\n",
    "        #Performing move function for certain number of step size   \n",
    "        self.generation += 1\n",
    "        self.working_generation['Generation'] += 1 \n",
    "        for i in range(len(self.working_generation)):\n",
    "            new_position = self.working_generation['Position'][i] + self.working_generation['Velocity'][i]*size\n",
    "            self.working_generation.at[i,'Position'] = np.around(new_position, decimals = 3)\n",
    "            \n",
    "            \"\"\"#Checking whether the new position cross the boundaries (UNFINISHED)\n",
    "            if new_position.max() > 1 or new_position.min() < 0:\n",
    "                new_position = self.working_generation['Position'][i] - self.working_generation['Velocity'][i]*size\n",
    "            self.working_generation.at[i,'Position'] = np.around(new_position, decimals = 3)\"\"\"\n",
    "        \n",
    "        #Filling the \"Activity\" column with RFR\n",
    "        self.f_activity(self.working_generation)\n",
    "        \n",
    "        #Concating the tables\n",
    "        self.datalog = pd.concat([self.datalog, self.working_generation])\n",
    "        self.datalog = self.datalog.reset_index(drop=True)\n",
    "        self.store_datalog()\n",
    "        return\n",
    "    \n",
    "    def f_activity(self, dataframe):\n",
    "        global reg\n",
    "        a = [0, 0, 0, 0, 0]\n",
    "        for i in range(len(dataframe)):\n",
    "            dataframe.at[i, 'Activity'] = float(reg.predict(np.reshape((np.hstack((dataframe.at[i, 'Position'], a))), (1, -1))))\n",
    "        return \n",
    "\n",
    "    def store_datalog(self):\n",
    "        self.datalog.to_csv(\"Result/Initial Population_gen \"+str(self.generation)+\".txt\", sep='\\t', index=False, mode='w')\n",
    "        return\n",
    "    \n",
    "    def normalize_velocity(self, dataframe):\n",
    "        for i in range(len(dataframe)):\n",
    "            dataframe.at[i, 'Velocity'] = dataframe.at[i, 'Velocity'] - (sum(dataframe.at[i, 'Velocity'])/len(dataframe['Elements'][0]))\n",
    "            dataframe.at[i, 'Velocity'] = np.around(dataframe.at[i, 'Velocity'], decimals= 3)\n",
    "        return\n",
    "    \n",
    "    def normalize_position(self, dataframe):\n",
    "        for i in range(len(dataframe)):\n",
    "            dataframe.at[i, 'Position'] = dataframe.at[i, 'Position']/(sum(dataframe.at[i, 'Position']))\n",
    "            dataframe.at[i, 'Position'] = np.around(dataframe.at[i, 'Position'], decimals= 3)\n",
    "        return \n",
    "           \n",
    "    \n",
    "    def g_best(self):\n",
    "        self.g_best = self.datalog['Position'][np.argmin(self.datalog['Activity'])]\n",
    "        return\n",
    "    \n",
    "    def gen_best(self):\n",
    "        self.gen_best = self.working_generation['Position'][np.argmin(self.working_generation['Activity'])]\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def i_best(self):\n",
    "        self.i_best = []\n",
    "        for i in range(len(self.working_generation)):\n",
    "            self.i_best.append(list(self.datalog['Position'][self.datalog['ID']==(i+1)].reset_index(drop=True)[np.argmin(self.datalog['Activity'][self.datalog['ID']==(i+1)])]))\n",
    "        self.i_best = np.array(self.i_best)   \n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105c574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_number = 6\n",
    "element = ['Pt', 'Pd', 'Au']\n",
    "creating_samples(samples_number, element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2188e5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step = 5\n",
    "target = np.array([0.9, 0.1, 0])\n",
    "population = pso(pd.read_csv('Result/Initial Population.txt', sep='\\t'), step, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7efec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "population.datalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17658fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "population.move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d58bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "population.working_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f49e00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "population.datalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7237a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb69e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344278b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
